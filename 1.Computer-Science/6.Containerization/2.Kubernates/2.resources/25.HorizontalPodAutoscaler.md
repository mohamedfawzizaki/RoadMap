___________________________________________________________________________________________________________________________

---

# What is HorizontalPodAutoscaler (HPA)?

The **HorizontalPodAutoscaler** automatically scales the number of pods in a deployment, replica set, or stateful set **based on observed metrics** like CPU utilization, memory usage, or custom metrics.

---

# Why use HPA?

* Automatically adjust the number of pod replicas to handle varying load.
* Improve resource utilization by scaling down when demand is low.
* Enhance application availability by scaling up during traffic spikes.
* Reduce manual intervention for scaling operations.

---

# Key Concepts

| Term            | Description                                                                |
| --------------- | -------------------------------------------------------------------------- |
| Target resource | The workload controller being scaled (Deployment, RS, StatefulSet)         |
| Metrics         | Resource metrics (CPU, memory) or custom/external metrics used for scaling |
| Min replicas    | Minimum number of pod replicas to maintain                                 |
| Max replicas    | Maximum number of pod replicas allowed                                     |
| Scale Target    | The resource object the HPA monitors and scales                            |

---

# HPA Anatomy (YAML Example)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 50  # target average CPU usage %
```

---

# Important Fields

| Field            | Description                                                   |
| ---------------- | ------------------------------------------------------------- |
| `scaleTargetRef` | The object (Deployment, ReplicaSet, StatefulSet) to autoscale |
| `minReplicas`    | Minimum number of pods to maintain                            |
| `maxReplicas`    | Maximum number of pods allowed                                |
| `metrics`        | Metrics used to trigger scaling                               |

---

# Metrics Types Supported

* **Resource metrics** (CPU, memory)
* **External metrics** (e.g., from cloud provider)
* **Custom metrics** (application-specific)
* **Object metrics** (metrics from Kubernetes objects, like queue length)

---

# How HPA Works

1. HPA queries the **metrics API** to get current metrics (like CPU usage) for pods.
2. It compares the current metrics to the **target metrics** defined in the HPA.
3. Calculates the desired number of replicas to meet the target.
4. Scales the targeted workload controller up or down accordingly.
5. Continues to monitor and adjust periodically (default every 15 seconds).

---

# Prerequisites

* Metrics server or custom metrics API must be installed and available.
* The target workload (e.g., Deployment) must have resource requests defined (especially CPU for CPU-based autoscaling).

---

# HPA Behavior and Scaling Algorithm

* If average CPU utilization is above target, HPA increases replicas.
* If utilization is below target, HPA decreases replicas but never below `minReplicas`.
* Scaling respects `maxReplicas` limit.
* To avoid thrashing, scaling events are rate-limited and have stabilization windows.

---

# Common Commands

* Create HPA:

```bash
kubectl apply -f hpa.yaml
```

* Get HPA status:

```bash
kubectl get hpa
kubectl describe hpa myapp-hpa
```

* Delete HPA:

```bash
kubectl delete hpa myapp-hpa
```

---

# Example: CPU-Based HPA for Deployment

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: frontend
  minReplicas: 3
  maxReplicas: 15
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
```

---

# Notes

* For HPA to work with CPU or memory metrics, pods must define resource **requests**.
* Custom and external metrics require additional setup (metrics adapters).
* HPA only controls **horizontal scaling** (number of pods), not vertical scaling (resources per pod).

---
